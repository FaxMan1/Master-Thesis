{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "southwest-omaha",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from Comms_System import Comms_System, butter_lowpass, SNR_plot_new\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from NetworkPytorch import joint_train_loop\n",
    "from DE_Pytorch import DE\n",
    "from scipy import signal\n",
    "import scipy\n",
    "import torchaudio\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "positive-newfoundland",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "\n",
    "    upsampled = CS.upsample()\n",
    "    X_tx = torch.Tensor(upsampled).view(1, 1, -1)\n",
    "    classes = np.array(symbol_set)\n",
    "    y = symbol_seq\n",
    "    class_idx = {v: i for i, v in enumerate(classes)}\n",
    "    y_idx = np.array([class_idx[v] for v in y])\n",
    "    y = torch.Tensor(y_idx)\n",
    "    \n",
    "    return X_tx, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "brown-leadership",
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol_set = [3, 1, -1, -3] # all symbols that we use\n",
    "num_symbols = 10000\n",
    "symbol_seq = np.random.choice(symbol_set, num_symbols, replace=True)\n",
    "m = 8\n",
    "CS = Comms_System(symbol_set=symbol_set, symbol_seq=symbol_seq, num_samples=m, beta=0.35, norm_h=False)\n",
    "\n",
    "# Create 1D Convolutional Neural Networks for transmitter and receiver and define optimizer and loss\n",
    "# Remember to double check padding and general design of NN_tx and NN_rx\n",
    "\n",
    "Xtrain, ytrain = get_data()\n",
    "Xtest, ytest = get_data()\n",
    "\n",
    "NN_tx = torch.nn.Sequential(torch.nn.Conv1d(1, 1, 64, padding=len(CS.h)-1)) # padding=len(CS.h) - 1\n",
    "NN_rx = torch.nn.Sequential(torch.nn.Conv1d(1, 1, 64), torch.nn.Conv1d(1, 4, 8, stride=8))\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "params = list(NN_tx.parameters()) + list(NN_rx.parameters())\n",
    "optimizer = torch.optim.Adam(params, lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87549b8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Joint train sender and receiver NN using Backpropagation\n",
    "\n",
    "epoch_losses = joint_train_loop(NN_tx, NN_rx, Xtrain, ytrain, optimizer, criterion, lowpass=True,\n",
    "                                sample_rate=CS.m, epochs=2000, cutoff_freq=2, v=True, use_cuda=False, SNRdb=10)\n",
    "\n",
    "plt.figure(figsize=(13, 8))\n",
    "plt.plot(epoch_losses.to('cpu'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rapid-production",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "\n",
    "def transmit_joint(upsampled, classes, SNRdb=10, cutoff_freq=2, v=False):\n",
    "    \n",
    "    SNR = 10 ** (SNRdb / 10)\n",
    "    sigma = np.sqrt(8 / SNR)\n",
    "    if v:\n",
    "        print(\"sigma:\", sigma)\n",
    "    \n",
    "    b, a = butter_lowpass(cutoff_freq, CS.m, 4)\n",
    "    b = torch.tensor(b, requires_grad=True).float()\n",
    "    a = torch.tensor(a, requires_grad=True).float()\n",
    "\n",
    "    Tx = NN_tx(upsampled)\n",
    "\n",
    "    #Send filtered signal through lowpass filter\n",
    "    Tx = torchaudio.functional.lfilter(Tx, a, b)\n",
    "    # Normalize signal\n",
    "    Tx = Tx / torch.sqrt(torch.mean(torch.square(Tx)))\n",
    "    # Transmit signal\n",
    "    Tx = Tx + torch.normal(0.0, sigma, Tx.shape)\n",
    "\n",
    "    output = NN_rx(Tx)[0].T\n",
    "    decisions = classes[output.argmax(axis=1)]\n",
    "    \n",
    "    return decisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yellow-kernel",
   "metadata": {},
   "outputs": [],
   "source": [
    "joint_decisions = transmit_joint(Xtest, np.array(CS.symbol_set))\n",
    "print(\"Accuracy:\", 1 - CS.evaluate(joint_decisions)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "institutional-decrease",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = CS.SNRdb_to_sigma(SNRdb=10, energy=1*8)\n",
    "joint_decisions = CS.transmit_joint(sigma, cutoff_freq=2)\n",
    "joint_decisions\n",
    "1 - CS.evaluate(joint_decisions)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00fcbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol_set = [3, 1, -1, -3]  # all symbols that we use\n",
    "num_symbols = 1000\n",
    "symbol_seq = np.random.choice(symbol_set, num_symbols, replace=True)\n",
    "m = 8\n",
    "CS = Comms_System(symbol_set=symbol_set, symbol_seq=symbol_seq, num_samples=m, beta=0.35, norm_h=False)\n",
    "\n",
    "SNRdbs = np.linspace(0, 18, 50)\n",
    "sigmas = []\n",
    "euclid_error_rates = []\n",
    "network_error_rates = []\n",
    "avg_symbol_energy = np.mean(np.array(symbol_seq) ** 2)\n",
    "print('Avg symbol energy', avg_symbol_energy)\n",
    "gain_factor = np.max(np.convolve(CS.h, CS.h))\n",
    "print('gain', gain_factor)\n",
    "Xtest, ytest, CStest = get_data(num_symbols=10000)\n",
    "\n",
    "for SNRdb in SNRdbs:\n",
    "    sigma_euclid = CS.SNRdb_to_sigma(SNRdb, avg_symbol_energy, use_gain=True) # symbol energy og gain\n",
    "    sigma_network = CS.SNRdb_to_sigma(SNRdb, 8, use_gain=False) # fordi vi har normaliseret er sample energi sat til 1, og vi har 8 samples pr symbol, er avg_symbol_energy s√• 1*8\n",
    "    euclid_decisions = CS.transmission(noise_level=sigma_euclid, norm_signal=False, v=False)\n",
    "    joint_decisions = transmit_joint(SNRdb, Xtest, ytest, CStest, cutoff_freq=2)\n",
    "    CStest.evaluate(joint_decisions)[1]\n",
    "    \n",
    "    #network_decisions = CS.transmission(mode='network', noise_level=sigma_network, norm_signal=True, v=False, model=model)\n",
    "    sigmas.append(sigma_euclid)\n",
    "\n",
    "    euclid_error_rates.append(CS.evaluate(euclid_decisions)[1])\n",
    "    network_error_rates.append(CStest.evaluate(joint_decisions)[1])\n",
    "\n",
    "sigmas = np.array(sigmas)\n",
    "error_theory = 1.5 * (1 - norm.cdf(np.sqrt(gain_factor / sigmas ** 2)))\n",
    "euclid_error_rates = np.array(euclid_error_rates)\n",
    "network_error_rates = np.array(network_error_rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3815733a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 11))\n",
    "plt.title('Noise Plot', fontsize=24)\n",
    "plt.xlabel('SNR (dB)', fontsize=20)\n",
    "plt.ylabel('$P_e$', fontsize=20)\n",
    "plt.semilogy(SNRdbs, euclid_error_rates)\n",
    "plt.semilogy(SNRdbs, error_theory)\n",
    "plt.semilogy(SNRdbs, network_error_rates)\n",
    "\n",
    "legend = ['Euclid', 'Theory', 'Joint Training']\n",
    "plt.legend(legend, fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8432da3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96580fbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cooked-neighborhood",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest, ytest, CStest = get_data(num_symbols=10000)\n",
    "\n",
    "sigmas = np.linspace(0.25, 1.75, 50)\n",
    "\n",
    "#sigmas = np.linspace(0.75, 4.5, 50) #sigmas = np.linspace(2.5, 4.5, 500)#\n",
    "SNRs = []\n",
    "error_rates_joint = []\n",
    "error_rates_euclid = []\n",
    "avg_symbol_energy = np.mean(np.array(CStest.symbol_seq)**2)\n",
    "gain_factor = np.max(np.convolve(CStest.h, CStest.h))\n",
    "print(gain_factor)\n",
    "\n",
    "for sigma in sigmas:\n",
    "\n",
    "    error_rates_joint.append( evaluate_yo(sigma, Xtest, ytest, CStest, 2) )\n",
    "    received_symbols_euclid = CStest.transmission(mode='euclidean', noise_level=sigma)\n",
    "    SNRs.append(avg_symbol_energy/(sigma**2))\n",
    "    error_rates_euclid.append(CStest.evaluate(received_symbols_euclid)[1])\n",
    "\n",
    "SNRsDB = 10*np.log10(SNRs)\n",
    "error_rates_joint = np.array(error_rates_joint)\n",
    "error_rates_euclid = np.array(error_rates_euclid)\n",
    "error_theory = 1.5 * (1 - scipy.stats.norm.cdf(np.sqrt(gain_factor/sigmas**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "internal-poultry",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13,8))\n",
    "plt.title('Decision-Making Noise Plots', fontsize=24)\n",
    "plt.xlabel('SNR (dB)', fontsize=20)\n",
    "plt.ylabel('$P_e$', fontsize=20)\n",
    "num = 0\n",
    "plt.semilogy(SNRsDB, error_rates_euclid)\n",
    "plt.semilogy(SNRsDB[num:], error_rates_joint[num:])\n",
    "plt.semilogy(SNRsDB, error_theory)\n",
    "legend = ['Euclidean', 'Sender AND Receiver Network', 'Theory']\n",
    "legend2 = ['Euclidean', 'Theory']\n",
    "plt.legend(legend2, fontsize=16)\n",
    "#plt.ylim([1e-3, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extended-guide",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
