{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brilliant-daisy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from Comms_System import Comms_System, SNR_plot\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ML_components import load_params\n",
    "from Network import NeuralNetwork\n",
    "import scipy\n",
    "import torch\n",
    "from filters import butter_lowpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "canadian-psychiatry",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Yo, welcome to Main CS')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demonstrated-science",
   "metadata": {},
   "source": [
    "## Automatic Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corporate-silence",
   "metadata": {},
   "outputs": [],
   "source": [
    "#symbol_set = [7, 5, 3, 1, -1, -3, -5, -7] # all symbols that we use\n",
    "symbol_set = [3, 1, -1, -3] # all symbols that we use\n",
    "num_symbols = 10000\n",
    "symbol_seq = np.random.choice(symbol_set, num_symbols, replace=True)\n",
    "m = 8\n",
    "CS = Comms_System(symbol_set=symbol_set, symbol_seq=symbol_seq, num_samples=m, beta=1)\n",
    "SNR = 10\n",
    "\n",
    "\n",
    "# can never not normalize and not use gain. Either one or both.\n",
    "decisions = CS.transmission(SNRdb=SNR, mode='joint', v=True)\n",
    "\n",
    "print(\"Accuracy:\", 1 - CS.evaluate(decisions)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "checked-journalism",
   "metadata": {},
   "source": [
    "### Manual Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electrical-clinton",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "symbol_set = [3, 1, -1, -3] # all symbols that we use\n",
    "num_symbols = 1000\n",
    "\n",
    "symbol_seq = np.random.choice(symbol_set, num_symbols, replace=True)\n",
    "m = 8\n",
    "CS = Comms_System(symbol_set=symbol_set, symbol_seq=symbol_seq, num_samples=m, beta=0.35)\n",
    "sigma = 2\n",
    "\n",
    "# calibrate\n",
    "gain_factor = np.max(np.convolve(CS.h, CS.h))\n",
    "\n",
    "# upsample symbol sequence and filter it on transmission side\n",
    "upsampled = CS.upsample()\n",
    "Tx = np.convolve(upsampled, CS.h)\n",
    "\n",
    "# Transmit the filtered signal (i.e. add noise)\n",
    "Tx = Tx + np.random.normal(0.0, sigma, Tx.shape)  # add gaussian noise\n",
    "\n",
    "# Filter on receiver side\n",
    "Rx = np.convolve(Tx, CS.h)#/np.sqrt(gain_factor)\n",
    "\n",
    "# Downsample the signal on the receiver side\n",
    "downsampled = CS.downsample(Rx)/gain_factor\n",
    "\n",
    "# Decision-making using new_values\n",
    "decisions = CS.decision_making(downsampled, False)\n",
    "\n",
    "#1 - CS.evaluate(decisions)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "heard-netherlands",
   "metadata": {},
   "source": [
    "### Manual Test with normalization of signal instead of gain_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controlling-afternoon",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "symbol_set = [3, 1, -1, -3] # all symbols that we use\n",
    "num_symbols = 1000\n",
    "\n",
    "symbol_seq = np.random.choice(symbol_set, num_symbols, replace=True)\n",
    "m = 8\n",
    "CS = Comms_System(symbol_set=symbol_set, symbol_seq=symbol_seq, num_samples=m, beta=0.35)\n",
    "symbol_seq_power = np.mean(np.square(symbol_seq))\n",
    "SNR = 10\n",
    "sigma = CS.SNRdb_to_sigma(SNR, 8, use_gain=False)\n",
    "print(sigma)\n",
    "\n",
    "# upsample symbol sequence and filter it on transmission side\n",
    "upsampled = CS.upsample(v=False)\n",
    "Tx = np.convolve(upsampled, CS.h)\n",
    "\n",
    "# Normalize signal with RMS\n",
    "Tx = Tx / np.sqrt(np.mean(np.square(Tx)))\n",
    "\n",
    "# Transmit the filtered signal (i.e. add noise)\n",
    "Tx = Tx + np.random.normal(0.0, sigma, Tx.shape)  # add gaussian noise\n",
    "\n",
    "# Filter on receiver side\n",
    "Rx = np.convolve(Tx, CS.h)\n",
    "\n",
    "# Normalize received signal with RMS * squareroot of symbol seq power?\n",
    "Rx = (Rx / np.sqrt(np.mean(np.square(Rx)))) * np.sqrt(symbol_seq_power)\n",
    "\n",
    "# Downsample the signal on the receiver side\n",
    "downsampled = CS.downsample(Rx)\n",
    "\n",
    "# Decision-making using new_values\n",
    "decisions = CS.decision_making(downsampled, False)\n",
    "\n",
    "1 - CS.evaluate(decisions)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decimal-integer",
   "metadata": {},
   "source": [
    "## Display filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "earlier-stereo",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "betas = [0, 0.35, 0.7, 1]\n",
    "plt.figure(figsize=(13,8))\n",
    "plt.title('Root Raised Cosine', fontsize=24)\n",
    "plt.xlabel('Time', fontsize=20)\n",
    "plt.ylabel('Amplitude', fontsize=20)\n",
    "z = np.zeros(len(CS.h))\n",
    "for beta in betas:\n",
    "    CS = Comms_System(symbol_set=symbol_set, symbol_seq=symbol_seq, num_samples=m, beta=beta)\n",
    "    #f = np.fft.fft(CS.h)\n",
    "    plt.plot(CS.h)\n",
    "plt.grid(True)\n",
    "plt.legend(betas, fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(13,8))\n",
    "plt.title('Raised Cosine', fontsize=24)\n",
    "plt.xlabel('Time', fontsize=20)\n",
    "plt.ylabel('Amplitude', fontsize=20)\n",
    "z = np.zeros(len(CS.h))\n",
    "CS = Comms_System(symbol_set=symbol_set, symbol_seq=symbol_seq, num_samples=m, beta=0.35)\n",
    "plt.stem(np.convolve(CS.h, CS.h))\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(13,8))\n",
    "plt.title('Root Raised Cosine (Frequency Spectrum)', fontsize=24)\n",
    "plt.xlabel('Frequency', fontsize=20)\n",
    "plt.ylabel('Magnitude (Energy)', fontsize=20)\n",
    "for beta in betas:\n",
    "    CS = Comms_System(symbol_set=symbol_set, symbol_seq=symbol_seq, num_samples=m, beta=beta)\n",
    "    plt.magnitude_spectrum(CS.h, CS.m, sides='twosided')\n",
    "plt.grid(True)\n",
    "plt.legend(betas, fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(13,8))\n",
    "plt.title('Raised Cosine (Frequency Spectrum)', fontsize=24)\n",
    "plt.xlabel('Frequency', fontsize=20)\n",
    "plt.ylabel('Magnitude (Energy)', fontsize=20)\n",
    "CS = Comms_System(symbol_set=symbol_set, symbol_seq=symbol_seq, num_samples=m, beta=0.35)\n",
    "plt.magnitude_spectrum(np.convolve(CS.h, CS.h), CS.m, sides='twosided', color='C1')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "related-learning",
   "metadata": {},
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mathematical-representative",
   "metadata": {},
   "source": [
    "# Evaluation of pretrained Decision Making models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seventh-intellectual",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "\n",
    "    symbol_set = [3, 1, -1, -3] # all symbols that we use\n",
    "    num_symbols = 10000\n",
    "    symbol_seq = np.random.choice(symbol_set, num_symbols, replace=True)\n",
    "    m = 8\n",
    "    CS = Comms_System(symbol_set=symbol_set, symbol_seq=symbol_seq, num_samples=m)\n",
    "    SNRdb = 16    \n",
    "    \n",
    "    euclid_decs, NN_decs, block_decs, network_decs, joint_decs = CS.transmit_all(SNRdb, joint_cutoff=2)\n",
    "    \n",
    "\n",
    "    print('Euclidean Error Rate: {}%'.format((CS.evaluate(euclid_decs)[1]*100).round(2)))\n",
    "    print('NN Error Rate: {}%'.format((CS.evaluate(euclid_decs)[1]*100).round(2)))\n",
    "    print('Block Error Rate: {}%'.format((CS.evaluate(block_decs)[1]*100).round(2)))\n",
    "    print('Receiver Network Error Rate: {}%'.format((CS.evaluate(network_decs)[1]*100).round(2)))\n",
    "    print('Joint Sender-Receiver Network Error Rate: {}%'.format((CS.evaluate(joint_decs)[1]*100).round(2)))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "young-shelter",
   "metadata": {},
   "source": [
    "### SNR Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becoming-party",
   "metadata": {},
   "outputs": [],
   "source": [
    "SNRdbs, euclid_error_rates, network_error_rates, NN_error_rates, block_error_rates, \\\n",
    "joint_error_rates, error_theory = SNR_plot(num_symbols=1000,\n",
    "                                           rx_cutoff=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "superb-price",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,10))\n",
    "plt.title('Joint Networks Noise Plot with cutoff  ' r'$\\frac{1}{2}$', fontsize=24)\n",
    "plt.xlabel('SNR (dB)', fontsize=20)\n",
    "plt.ylabel('$P_e$', fontsize=20)\n",
    "num = 0\n",
    "plt.semilogy(SNRdbs[num:], euclid_error_rates[num:], alpha=1, linewidth=3)\n",
    "#plt.semilogy(SNRdbs[num:], NN_error_rates[num:])\n",
    "#plt.semilogy(SNRdbs[num:], block_error_rates[num:])\n",
    "#plt.semilogy(SNRdbs[num:], network_error_rates[num:], alpha=1, linewidth=3)\n",
    "plt.semilogy(SNRdbs[num:], joint_error_rates[num:], alpha=1, linewidth=3)\n",
    "plt.semilogy(SNRdbs[num:], error_theory[num:], alpha=0.5, linewidth=3)\n",
    "legend1 = ['Euclidean','Joint Networks', 'Theory']\n",
    "legend2 = ['Euclidean', 'Receiver Network', 'Joint Network', 'Theory']\n",
    "legend3 = ['Euclidean', 'NN Dec Maker', 'Block', 'Receiver Network', 'Joint Network', 'Theory']\n",
    "plt.legend(legend1, fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "warming-dutch",
   "metadata": {},
   "outputs": [],
   "source": [
    "er_for_sigma3 = 1.5 * (1 - scipy.stats.norm.cdf(np.sqrt(8/(3**2))))\n",
    "er_for_sigma2 = 1.5 * (1 - scipy.stats.norm.cdf(np.sqrt(8/(2**2))))\n",
    "er_for_sigma1 = 1.5 * (1 - scipy.stats.norm.cdf(np.sqrt(8/(1**2))))\n",
    "print(1-er_for_sigma1, 1-er_for_sigma2, 1-er_for_sigma3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accessible-ideal",
   "metadata": {},
   "source": [
    "# Inspect Decision Boundaries for NN Decision Making"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "allied-electric",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights, biases, sizes = load_params('../Weights/decision_making_weights.npz',\n",
    "                                         '../Weights/decision_making_biases.npz')\n",
    "NN = NeuralNetwork(sizes, startweights=weights, startbiases=biases,\n",
    "                           type='classification', afunc='relu')\n",
    "classes = np.array(symbol_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thirty-seller",
   "metadata": {},
   "source": [
    "## Plot 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "muslim-pound",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_seq = np.linspace(-4, 4, 40)\n",
    "test_seq = np.array(test_seq, ndmin=2).T\n",
    "yhat_onehot = NN.feedforward(test_seq)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(13,8))\n",
    "plt.title('Decision Boundaries', fontsize=24)\n",
    "for i in range(yhat_onehot.shape[1]):\n",
    "    plt.plot(test_seq, yhat_onehot[:,i], '-x')\n",
    "#plt.axvline(x=-2, color='black')\n",
    "#plt.axvline(x=0, color='black')\n",
    "#plt.axvline(x=2, color='black')\n",
    "plt.xlabel('Input', fontsize=20)\n",
    "plt.ylabel('Probability of choosing', fontsize=20)\n",
    "plt.legend(symbol_set + ['Euclidean Boundaries'], fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extraordinary-precipitation",
   "metadata": {},
   "source": [
    "## Plot 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "integrated-leadership",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = np.array(symbol_set)\n",
    "test_seq = np.linspace(-4, 4+1, 100)\n",
    "test_seq = np.array(test_seq, ndmin=2).T\n",
    "\n",
    "yhat_idx = NN.feedforward(test_seq).argmax(axis=1)\n",
    "yhat = classes[yhat_idx]\n",
    "euclid_decisions = CS.decision_making(test_seq)\n",
    "\n",
    "\n",
    "num = len(test_seq)\n",
    "plt.figure(figsize=(13,8))\n",
    "plt.xlabel('Sample Value (input)', fontsize=20)\n",
    "plt.ylabel('Decided value (output)', fontsize=20)\n",
    "plt.plot(test_seq[:num], yhat[:num], '-rx', alpha=0.5)\n",
    "plt.plot(test_seq[:num], euclid_decisions[:num], '-bx', alpha=1)\n",
    "plt.legend(['Neural Network', 'Euclidean'], fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "increasing-savage",
   "metadata": {},
   "source": [
    "# Inspect learned filters from Joint Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outstanding-pursuit",
   "metadata": {},
   "source": [
    "### Sender Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rubber-utility",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cutoffs = ['2', '1', '05', '03', '02']\n",
    "cutoff_ints = [2, 1, 0.5, 0.3, 0.2]\n",
    "#cutoffs = ['1']\n",
    "#cutoff_ints = [1]\n",
    "\n",
    "for cutoff, c_int in zip(cutoffs, cutoff_ints):\n",
    "    print('Cutoff Frequency =', c_int)\n",
    "    path = '../Joint_Models/'\n",
    "    net = torch.load(path + 'Sender_cutoff' + cutoff)\n",
    "    learned_filter = list(net.parameters())[0].detach()[0][0]\n",
    "    plt.figure()\n",
    "    #plt.figure(figsize=(13,8))\n",
    "    plt.title('Time', fontsize=16)\n",
    "    plt.plot(learned_filter)\n",
    "    plt.show()\n",
    "    plt.figure()\n",
    "    #plt.figure(figsize=(13,8))\n",
    "    plt.title('Frequency', fontsize=16)\n",
    "    plt.magnitude_spectrum(learned_filter, Fs=CS.m, color='C1', sides='twosided', scale='dB')\n",
    "    plt.show()\n",
    "    print('_________________________________________________________')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "endless-wagon",
   "metadata": {},
   "source": [
    "### Receiver Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hollywood-johnson",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cutoffs = ['2', '1', '05', '03', '02']\n",
    "cutoff_ints = [2, 1, 0.5, 0.3, 0.2]\n",
    "\n",
    "for cutoff, c_int in zip(cutoffs, cutoff_ints):\n",
    "    print('Cutoff Frequency =', c_int)\n",
    "    path = '../Joint_Models/'\n",
    "    net = torch.load(path + 'Receiver_cutoff' + cutoff)\n",
    "    learned_filter = list(net.parameters())[0].detach()[0][0]\n",
    "    #plt.figure(figsize=(13,8))\n",
    "    plt.figure()\n",
    "    plt.title(\"Time\", fontsize=16)\n",
    "    plt.plot(learned_filter)\n",
    "    plt.show()\n",
    "    plt.figure()\n",
    "    plt.title('Frequency', fontsize=16)\n",
    "    #plt.figure(figsize=(13,8))\n",
    "    plt.magnitude_spectrum(learned_filter, Fs=CS.m, color='C1', sides='twosided', scale='dB')\n",
    "    plt.show()\n",
    "    print('_________________________________________________________')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imported-bailey",
   "metadata": {},
   "source": [
    "### Total Impulse Response of Sender (i.e. sender filter convolved with LPF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "middle-sleeping",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cutoffs = ['2', '1', '05', '03', '02']\n",
    "cutoff_ints = [2, 1, 0.5, 0.3, 0.2]\n",
    "#cutoffs = ['03']\n",
    "#cutoff_ints = [0.3]\n",
    "\n",
    "\n",
    "for cutoff, c_int in zip(cutoffs, cutoff_ints):\n",
    "    print('Cutoff Frequency =', c_int)\n",
    "    b, a = butter_lowpass(cutoff_freq=1, sampling_rate=CS.m, order=10)\n",
    "    path = '../Joint_Models/'\n",
    "    net = torch.load(path + 'Sender_cutoff' + cutoff)\n",
    "    learned_filter = list(net.parameters())[0].detach()[0][0]\n",
    "    total_sender_response = scipy.signal.lfilter(b, a, learned_filter)\n",
    "    plt.figure()\n",
    "    plt.title('Full Sender Response (Time)', fontsize=16)\n",
    "    plt.plot(total_sender_response)\n",
    "    plt.show()\n",
    "    #plt.figure(figsize=(13,8))\n",
    "    plt.figure()\n",
    "    plt.title('Full Sender Response (Frequency)', fontsize=16)\n",
    "    plt.magnitude_spectrum(total_sender_response, Fs=8, scale='dB', sides='twosided', color='C1')\n",
    "    plt.show()\n",
    "    print('_________________________________________________________')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prescription-lafayette",
   "metadata": {},
   "source": [
    "### Total Response of Whole System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boxed-civilization",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cutoffs = ['2', '1', '05', '03', '02']\n",
    "cutoff_ints = [2, 1, 0.5, 0.3, 0.2]\n",
    "#cutoffs = ['03']\n",
    "#cutoff_ints = [0.3]\n",
    "\n",
    "\n",
    "for cutoff, c_int in zip(cutoffs, cutoff_ints):\n",
    "    print('Cutoff Frequency =', c_int)\n",
    "    b, a = butter_lowpass(cutoff_freq=1, sampling_rate=CS.m, order=10)\n",
    "    path = '../Joint_Models/'\n",
    "    tx_net = torch.load(path + 'Sender_cutoff'+cutoff)\n",
    "    rx_net = torch.load(path + 'Receiver_cutoff'+cutoff)\n",
    "    learned_tx_filter = list(tx_net.parameters())[0].detach()[0][0]\n",
    "    learned_rx_filter = list(rx_net.parameters())[0].detach()[0][0]\n",
    "    total_sender_response = scipy.signal.lfilter(b, a, learned_tx_filter)\n",
    "    full_response = np.convolve(total_sender_response, learned_rx_filter)\n",
    "    plt.figure()\n",
    "    plt.title('Full Reponse of System (Time)', fontsize=16)\n",
    "    plt.plot(full_response)\n",
    "    plt.show()\n",
    "    plt.figure()\n",
    "    plt.title('Full Response of System (Frequency)', fontsize=16)\n",
    "    #plt.figure(figsize=(13,8))\n",
    "    plt.magnitude_spectrum(full_response, Fs=8, scale='dB', sides='twosided', color='C1')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adequate-reserve",
   "metadata": {},
   "source": [
    "##### Want to time something? Use following code stump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demanding-class",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit -o -r 5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
