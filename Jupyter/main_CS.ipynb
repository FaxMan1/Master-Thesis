{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "brilliant-daisy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from Comms_System import Comms_System\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.axes as axes\n",
    "import scipy.stats\n",
    "from tqdm import tqdm\n",
    "from ML_components import load_params\n",
    "from Network import NeuralNetwork"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demonstrated-science",
   "metadata": {},
   "source": [
    "## Automatic Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "corporate-silence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57, 0.0057)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "symbol_set = [7, 5, 3, 1, -1, -3, -5, -7] # all symbols that we use\n",
    "num_symbols = 10000\n",
    "symbol_seq = np.random.choice(symbol_set, num_symbols, replace=True)\n",
    "m = 8\n",
    "CS = Comms_System(symbol_set=symbol_set, symbol_seq=symbol_seq, num_samples=m)\n",
    "\n",
    "decisions = CS.transmission(noise_level=1, mode='euclidean')\n",
    "CS.evaluate(decisions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "checked-journalism",
   "metadata": {},
   "source": [
    "### Manual Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "controlling-afternoon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0.0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "symbol_set = [3, 1, -1, -3] # all symbols that we use\n",
    "num_symbols = 10000\n",
    "symbol_seq = np.random.choice(symbol_set, num_symbols, replace=True)\n",
    "m = 8\n",
    "CS = Comms_System(symbol_set=symbol_set, symbol_seq=symbol_seq, num_samples=m, beta=0.35)\n",
    "\n",
    "# calibrate\n",
    "gain_factor = np.max(np.convolve(CS.h, CS.h))\n",
    "\n",
    "# upsample symbol sequence and filter it on transmission side\n",
    "upsampled = CS.upsample(v=False)\n",
    "Tx = np.convolve(upsampled, CS.h)\n",
    "\n",
    "# Transmit the filtered signal (i.e. add noise)\n",
    "Tx = Tx + np.random.normal(0.0, 0, Tx.shape)  # add gaussian noise\n",
    "\n",
    "# Filter on receiver side\n",
    "Rx = np.convolve(Tx, CS.h)\n",
    "\n",
    "# Downsample the signal on the receiver side\n",
    "downsampled = CS.downsample(Rx)\n",
    "\n",
    "# Decision-making using new_values\n",
    "decisions = CS.decision_making(downsampled/gain_factor, False)\n",
    "\n",
    "CS.evaluate(decisions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decimal-integer",
   "metadata": {},
   "source": [
    "## Display filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "earlier-stereo",
   "metadata": {},
   "outputs": [],
   "source": [
    "betas = [0, 0.35, 0.7, 1]\n",
    "plt.figure(figsize=(13,8))\n",
    "plt.title('Root Raised Cosine', fontsize=24)\n",
    "plt.xlabel('Time', fontsize=20)\n",
    "plt.ylabel('Amplitude', fontsize=20)\n",
    "z = np.zeros(len(CS.h))\n",
    "for beta in betas:\n",
    "    CS = Comms_System(symbol_set=symbol_set, symbol_seq=symbol_seq, num_samples=m, beta=beta)\n",
    "    #f = np.fft.fft(CS.h)\n",
    "    plt.plot(CS.h)\n",
    "plt.grid(True)\n",
    "plt.legend(betas, fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(13,8))\n",
    "plt.title('Raised Cosine', fontsize=24)\n",
    "plt.xlabel('Time', fontsize=20)\n",
    "plt.ylabel('Amplitude', fontsize=20)\n",
    "z = np.zeros(len(CS.h))\n",
    "CS = Comms_System(symbol_set=symbol_set, symbol_seq=symbol_seq, num_samples=m, beta=0.35)\n",
    "plt.stem(np.convolve(CS.h, CS.h))\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "related-learning",
   "metadata": {},
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mathematical-representative",
   "metadata": {},
   "source": [
    "# Evaluation of pretrained Decision Making model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "functional-proportion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Dragonborn/Documents/Master Thesis/Code/DE_PyCharm/Jupyter\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../SavedWeights/block_decision_making_weights.npz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-fc3bcd46e4de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# Automatic test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mdecisions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNN_decisions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownsampled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock_decisions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_CS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise_level\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnoise_level\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Euclidean Distance Error Rate: {}%'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecisions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m#print('Neural Net Error Rate: {}%'.format((CS.evaluate(NN_decisions)[1]*100).round(2)))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Master Thesis/Code/DE_PyCharm/Comms_System.py\u001b[0m in \u001b[0;36mtest_CS\u001b[0;34m(self, noise_level, model, v, mode)\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mRx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0mblocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_periods\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRx\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mgain_factor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m         \u001b[0mblock_decisions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mML_downsampling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymbol_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_filtered\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Filtered Signal with Noise'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Master Thesis/Code/DE_PyCharm/ML_components.py\u001b[0m in \u001b[0;36mML_downsampling\u001b[0;34m(blocks, classes, model)\u001b[0m\n\u001b[1;32m     23\u001b[0m    \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m    w, b, sizes = load_params('../SavedWeights/block_decision_making_weights.npz',\n\u001b[0;32m---> 25\u001b[0;31m                              '../SavedWeights/block_decision_making_biases.npz')\n\u001b[0m\u001b[1;32m     26\u001b[0m    best_agent = NeuralNetwork(sizes, startweights=w, startbiases=b,\n\u001b[1;32m     27\u001b[0m                               type='classification', afunc='relu')\n",
      "\u001b[0;32m~/Documents/Master Thesis/Code/DE_PyCharm/ML_components.py\u001b[0m in \u001b[0;36mload_params\u001b[0;34m(weight_file, bias_file)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mw_container\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mb_container\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mw_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mw_container\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    414\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../SavedWeights/block_decision_making_weights.npz'"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "\n",
    "    symbol_set = [3, 1, -1, -3] # all symbols that we use\n",
    "    num_symbols = 10000\n",
    "    symbol_seq = np.random.choice(symbol_set, num_symbols, replace=True)\n",
    "    m = 8\n",
    "    CS = Comms_System(symbol_set=symbol_set, symbol_seq=symbol_seq, num_samples=m)\n",
    "    noise_level = 1\n",
    "\n",
    "    # Automatic test\n",
    "    decisions, NN_decisions, downsampled, block_decisions = CS.test_CS(noise_level=noise_level, v=False)\n",
    "    print('Euclidean Distance Error Rate: {}%'.format((CS.evaluate(decisions)[1]*100).round(2)))\n",
    "    #print('Neural Net Error Rate: {}%'.format((CS.evaluate(NN_decisions)[1]*100).round(2)))\n",
    "    print('Neural Net Block Error Rate: {}%'.format((CS.evaluate(block_decisions)[1]*100).round(2)))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "young-shelter",
   "metadata": {},
   "source": [
    "### SNR Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "revolutionary-geometry",
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol_set = [3, 1, -1, -3] # all symbols that we use\n",
    "num_symbols = 10000\n",
    "symbol_seq = np.random.choice(symbol_set, num_symbols, replace=True)\n",
    "m = 8\n",
    "CS = Comms_System(symbol_set=symbol_set, symbol_seq=symbol_seq, num_samples=m, beta=0.35)\n",
    "\n",
    "sigmas = np.linspace(0.75, 4.5, 10) #sigmas = np.linspace(2.5, 4.5, 500)#\n",
    "SNRs = []\n",
    "error_rates = []\n",
    "error_rates_NN = []\n",
    "error_rates_NN_blocks = []\n",
    "avg_symbol_energy = np.mean(np.array(symbol_seq)**2)\n",
    "gain_factor = np.max(np.convolve(CS.h, CS.h))\n",
    "\n",
    "for sigma in sigmas:\n",
    "\n",
    "    decisions, NN_decisions, downsampled, NN_block_decisions = CS.test_CS(noise_level=sigma, v=False)\n",
    "    SNRs.append(avg_symbol_energy*gain_factor/(sigma**2))\n",
    "    error_rates.append(CS.evaluate(decisions)[1])\n",
    "    error_rates_NN.append(CS.evaluate(NN_decisions)[1])\n",
    "    error_rates_NN_blocks.append(CS.evaluate(NN_block_decisions)[1])\n",
    "    \n",
    "    \n",
    "SNRsDB = 10*np.log10(SNRs)\n",
    "error_rates = np.array(error_rates)\n",
    "error_rates_NN = np.array(error_rates_NN)\n",
    "error_rates_NN_blocks = np.array(error_rates_NN_blocks)\n",
    "error_theory = 1.5 * (1 - scipy.stats.norm.cdf(np.sqrt(gain_factor/sigmas**2))) # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wrapped-handbook",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13,8))\n",
    "plt.title('Decision Making Noise Plots', fontsize=24)\n",
    "plt.xlabel('SNR (dB)', fontsize=20)\n",
    "plt.ylabel('$P_e$', fontsize=20)\n",
    "num = 0\n",
    "plt.semilogy(SNRsDB[num:], error_rates[num:], alpha=1)\n",
    "#plt.semilogy(SNRsDB[num:], error_rates_NN[num:], alpha=1)\n",
    "plt.semilogy(SNRsDB[num:], error_rates_NN_blocks[num:])\n",
    "plt.semilogy(SNRsDB[num:], error_theory[num:])\n",
    "legend = ['Euclidean', 'Neural Network', 'Neural Network Blocks' ,'Theory']\n",
    "plt.legend(legend, fontsize=12)\n",
    "#plt.ylim([1e-3, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accessible-ideal",
   "metadata": {},
   "source": [
    "# Inspect Decision Boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "allied-electric",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights, biases, sizes = load_params('../SavedWeights/decision_making_weights.npz',\n",
    "                                         '../SavedWeights/decision_making_biases.npz')\n",
    "NN = NeuralNetwork(sizes, startweights=weights, startbiases=biases,\n",
    "                           type='classification', afunc='relu')\n",
    "classes = np.array(symbol_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thirty-seller",
   "metadata": {},
   "source": [
    "## Plot 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "muslim-pound",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_seq = np.linspace(-4, 4, 1000)\n",
    "test_seq = np.array(test_seq, ndmin=2).T\n",
    "yhat_onehot = NN.feedforward(test_seq)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(13,8))\n",
    "plt.title('Decision Boundaries', fontsize=24)\n",
    "for i in range(yhat_onehot.shape[1]):\n",
    "    plt.plot(test_seq, yhat_onehot[:,i], '-x')\n",
    "#plt.axvline(x=-2, color='black')\n",
    "#plt.axvline(x=0, color='black')\n",
    "#plt.axvline(x=2, color='black')\n",
    "plt.xlabel('Input', fontsize=20)\n",
    "plt.ylabel('Probability of choosing', fontsize=20)\n",
    "plt.legend(symbol_set + ['Euclidean Boundaries'], fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extraordinary-precipitation",
   "metadata": {},
   "source": [
    "## Plot 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "integrated-leadership",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = np.array(symbol_set)\n",
    "test_seq = np.linspace(-4, 4+1, 100)\n",
    "test_seq = np.array(test_seq, ndmin=2).T\n",
    "\n",
    "yhat_idx = NN.feedforward(test_seq).argmax(axis=1)\n",
    "yhat = classes[yhat_idx]\n",
    "euclid_decisions = CS.decision_making(test_seq)\n",
    "\n",
    "\n",
    "num = len(test_seq)\n",
    "plt.figure(figsize=(13,8))\n",
    "plt.xlabel('Sample Value (input)', fontsize=20)\n",
    "plt.ylabel('Decided value (output)', fontsize=20)\n",
    "plt.plot(test_seq[:num], yhat[:num], '-rx', alpha=0.5)\n",
    "plt.plot(test_seq[:num], euclid_decisions[:num], '-bx', alpha=1)\n",
    "plt.legend(['Neural Network', 'Euclidean'], fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adequate-reserve",
   "metadata": {},
   "source": [
    "##### Want to time something? Use following code stump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demanding-class",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit -o -r 5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
